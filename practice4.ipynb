{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e10b05bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set device for GPU acceleration if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d107ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"D:/ml_med_data/luna\"\n",
    "PATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be366d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = pd.read_csv(\"D:\\\\ml_med_data\\\\luna\\\\annotations.csv\")\n",
    "ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f5805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scan(mhd_path):\n",
    "    \"\"\"Loads a .mhd/.raw pair and returns the volumetric data.\"\"\"\n",
    "    meta = {}\n",
    "    with open(mhd_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if '=' in line:\n",
    "                k, v = line.strip().split(' = ')\n",
    "                meta[k] = v\n",
    "\n",
    "    dims = list(map(int, meta['DimSize'].split()))\n",
    "    base_dir = os.path.dirname(mhd_path)\n",
    "    raw_file_path = os.path.join(base_dir, meta['ElementDataFile'])\n",
    "    \n",
    "    with open(raw_file_path, 'rb') as f:\n",
    "        data = np.fromfile(f, dtype=np.int16)\n",
    "\n",
    "    # Reshape to (Z, Y, X)\n",
    "    volume = data.reshape(dims[::-1])\n",
    "    return volume, meta\n",
    "\n",
    "def normalize_hu(img):\n",
    "    \"\"\"Clips Hounsfield Units and scales to [0, 1].\"\"\"\n",
    "    img = np.clip(img, -1000, 400)\n",
    "    img = (img + 1000) / 1400\n",
    "    return img\n",
    "\n",
    "def extract_3d_patch(volume, center_zyx, patch_size=64):\n",
    "    \"\"\"Extracts a 3D cube from the volume centered at specific coordinates.\"\"\"\n",
    "    z, y, x = map(int, center_zyx)\n",
    "    half = patch_size // 2\n",
    "    \n",
    "    # Pad volume to handle edge cases\n",
    "    padded_vol = np.pad(volume, half, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Adjust for padding\n",
    "    z, y, x = z + half, y + half, x + half\n",
    "    patch = padded_vol[z-half:z+half, y-half:y+half, x-half:x+half]\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08a5f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Scans: 100%|██████████| 12/12 [00:31<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load annotations\n",
    "ann = pd.read_csv(os.path.join(DATA_DIR, \"annotations.csv\"))\n",
    "mhd_files = glob.glob(os.path.join(DATA_DIR, \"*.mhd\"))\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for fpath in tqdm(mhd_files, desc=\"Processing Scans\"):\n",
    "    uid = os.path.basename(fpath).replace('.mhd', '')\n",
    "    volume, _ = load_scan(fpath)\n",
    "    volume = normalize_hu(volume)\n",
    "    \n",
    "    # Positive Patches: Centered on known nodules\n",
    "    nodules = ann[ann['seriesuid'] == uid]\n",
    "    for _, row in nodules.iterrows():\n",
    "        # LUNA coords (X,Y,Z) -> Voxel indices usually requires origin/spacing conversion\n",
    "        # This assumes your coords are already mapped or close to voxel space\n",
    "        coord = (row['coordZ'], row['coordY'], row['coordX']) \n",
    "        patch = extract_3d_patch(volume, coord, PATCH_SIZE)\n",
    "        if patch.shape == (PATCH_SIZE, PATCH_SIZE, PATCH_SIZE):\n",
    "            X.append(patch)\n",
    "            y.append(1)\n",
    "\n",
    "    # Negative Patches: Random background crops\n",
    "    for _ in range(len(nodules)): \n",
    "        rand_coord = [np.random.randint(0, s) for s in volume.shape]\n",
    "        patch = extract_3d_patch(volume, rand_coord, PATCH_SIZE)\n",
    "        if patch.shape == (PATCH_SIZE, PATCH_SIZE, PATCH_SIZE):\n",
    "            X.append(patch)\n",
    "            y.append(0)\n",
    "\n",
    "X = np.expand_dims(np.array(X), axis=1) # Add channel dim\n",
    "y = np.array(y)\n",
    "\n",
    "# Create PyTorch Dataset\n",
    "dataset = TensorDataset(torch.tensor(X).float(), torch.tensor(y).float().view(-1, 1))\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a44b12e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x000001E868450720>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ngtru\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\ngtru\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\notebook.py\", line 277, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    }
   ],
   "source": [
    "class NoduleNet3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(2),\n",
    "            nn.Conv3d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = NoduleNet3D().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d3bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6880\n",
      "Epoch 2/10, Loss: 0.6713\n",
      "Epoch 3/10, Loss: 0.6580\n",
      "Epoch 4/10, Loss: 0.6501\n",
      "Epoch 5/10, Loss: 0.6446\n",
      "Epoch 6/10, Loss: 0.6363\n",
      "Epoch 7/10, Loss: 0.6315\n",
      "Epoch 8/10, Loss: 0.6272\n",
      "Epoch 9/10, Loss: 0.6257\n",
      "Epoch 10/10, Loss: 0.6197\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_3d(detections, threshold_dist=20):\n",
    "    \"\"\"Filters overlapping 3D detections (Non-Maximum Suppression).\"\"\"\n",
    "    if not detections: return []\n",
    "    detections = sorted(detections, key=lambda x: x[3], reverse=True)\n",
    "    keep = []\n",
    "    while detections:\n",
    "        best = detections.pop(0)\n",
    "        keep.append(best)\n",
    "        detections = [d for d in detections if np.linalg.norm(np.array(best[:3]) - np.array(d[:3])) > threshold_dist]\n",
    "    return keep\n",
    "\n",
    "def detect_nodules(volume, model, stride=32):\n",
    "    \"\"\"Applies model over volume using sliding window.\"\"\"\n",
    "    model.eval()\n",
    "    detections = []\n",
    "    sz = PATCH_SIZE\n",
    "    with torch.no_grad():\n",
    "        for z in range(0, volume.shape[0] - sz, stride):\n",
    "            for y in range(0, volume.shape[1] - sz, stride):\n",
    "                for x in range(0, volume.shape[2] - sz, stride):\n",
    "                    patch = volume[z:z+sz, y:y+sz, x:x+sz]\n",
    "                    patch_t = torch.from_numpy(patch).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "                    prob = model(patch_t).item()\n",
    "                    if prob > 0.8: # Confidence threshold\n",
    "                        detections.append((z + sz//2, y + sz//2, x + sz//2, prob))\n",
    "    return nms_3d(detections)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
